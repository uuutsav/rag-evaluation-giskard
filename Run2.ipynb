{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d151f8-a7fe-490d-a837-d5251683916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "886198d2-0e39-4821-8525-f80da1bce57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.5\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "print(pydantic.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d657fb74-5b29-4d35-80df-da4381993ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import giskard\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"USER_AGENT\"] = \"my-rag-evaluation-app\"\n",
    "\n",
    "# Use the standard gemini 2.5 flash model\n",
    "giskard.llm.set_llm_model(\"gemini/gemini-2.5-flash\")\n",
    "\n",
    "# Tell Giskard to use the universally available Google embedding model\n",
    "# giskard.llm.set_embedding_model(\"gemini/embedding-001\")\n",
    "# giskard.llm.set_embedding_model(\"gemini/text-embedding-004\")\n",
    "giskard.llm.set_embedding_model(\"gemini/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "492c7443-1b71-453c-9141-3fbbc7ead5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scrape the Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07dcda0-c597-4805-9195-e0d8566bbae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 34 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# UPDATE: The new, correct import path for modern LangChain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "# loader = WebBaseLoader(\"https://www.ml.school/\") #1\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\") #2\n",
    "# loader = WebBaseLoader(\"https://docs.python.org/3/tutorial/datastructures.html\") #3\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "print(f\"Scraped {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec886a23-83a5-4f0e-9e8f-b2aff6ecd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Embed using Gemini and Store in Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34e5ae7b-92b6-462a-a816-68f84e8db121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded and stored in VectorDB!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# Must include the \"models/\" prefix!\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    documents, embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"Successfully embedded and stored in VectorDB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85b8cb6f-113e-4a4b-95b4-34b98d64a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create the Knowledge Base & Generate Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55efbd4a-082d-424a-83cb-9feb54fa5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-25 14:34:41,324 pid:218502 MainThread giskard.rag  INFO     Finding topics in the knowledge base.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utsav/Desktop/Rise23+2/AI/Hehe/Giskard/rag-evaluation-gemini/.venv/lib/python3.10/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-25 14:34:52,706 pid:218502 MainThread giskard.rag  INFO     Found 3 topics in the knowledge base.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e199787c37464b04817247ed8c934467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating questions:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Question: What political topics are mentioned in the provided list?\n",
      "Expected Answer: The political topics mentioned are AI safety (Alignment), Ethics of AI, EU AI Act, Precautionary principle, and Regulation of AI.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from giskard.rag import KnowledgeBase, generate_testset\n",
    "\n",
    "df = pd.DataFrame([d.page_content for d in documents], columns=[\"text\"])\n",
    "knowledge_base = KnowledgeBase(df)\n",
    "\n",
    "# Generate the test set (using 15 questions for speed; scale up later)\n",
    "# testset = generate_testset(\n",
    "#     knowledge_base,\n",
    "#     num_questions=10,\n",
    "#     agent_description=\"A chatbot answering questions about the Machine Learning School Website\",\n",
    "# )\n",
    "# 2\n",
    "testset = generate_testset(\n",
    "    knowledge_base,\n",
    "    num_questions=15,\n",
    "    agent_description=\"A technical assistant answering questions about the concept of Retrieval-Augmented Generation (RAG) based on a Wikipedia article\",\n",
    ")\n",
    "\n",
    "testset.save(\"wiki-rag-test-set.jsonl\")\n",
    "\n",
    "# Let's peek at a generated question\n",
    "test_set_df = testset.to_pandas()\n",
    "print(\"Sample Question:\", test_set_df.iloc[0]['question'])\n",
    "print(\"Expected Answer:\", test_set_df.iloc[0]['reference_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d854217-b3eb-4371-8192-5b8a00000295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Build the Gemini RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aace52f-7bcb-450c-bdcd-bf7ff95816af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing chain:\n",
      "The main benefits of Retrieval-Augmented Generation (RAG) are:\n",
      "\n",
      "*   It helps reduce AI hallucinations.\n",
      "*   It reduces the need to retrain large language models (LLMs) with new data, saving on computational and financial costs.\n",
      "*   It allows LLMs to include sources in their responses, providing greater transparency and enabling users to verify the cited sources for accuracy and relevance.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Use Gemini 2.5 Flash\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test the chain manually\n",
    "print(\"Testing chain:\")\n",
    "print(chain.invoke({\"question\": \"What are the main benefits of Retrieval-Augmented Generation?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66147a50-9f2a-47d8-a1ec-16691ed10268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc2f026f-2793-4a2a-b7ea-222554cfa57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f26e6b80834be994cebbc336c9ec64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Asking questions to the agent:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2409f3d3d440e78fb4bacdd7aa717b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CorrectnessMetric evaluation:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"fb3b5b81-4b34-4bef-b971-91182dbdb6e5\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"fb3b5b81-4b34-4bef-b971-91182dbdb6e5\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"fb3b5b81-4b34-4bef-b971-91182dbdb6e5\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"fb3b5b81-4b34-4bef-b971-91182dbdb6e5\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"fb3b5b81-4b34-4bef-b971-91182dbdb6e5\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "\n",
       "\n",
       "<style>\n",
       "    body{\n",
       "  background: #18181B;\n",
       "}\n",
       "\n",
       ".main{\n",
       "  font-family: \"Noto Sans\", ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif, \"Apple Color Emoji\", \"Segoe UI Emoji\", \"Segoe UI Symbol\", \"Noto Color Emoji\";\n",
       "  color: #FDFDFD;\n",
       "}\n",
       "\n",
       "h1 {\n",
       "  font-size: 2.5rem;\n",
       "  color: white;\n",
       "}\n",
       "\n",
       "h3 {\n",
       "  font-size: 1.5rem;\n",
       "  background: #0c087c;\n",
       "  padding: 10px;\n",
       "  margin: 0px;\n",
       "  border: 1px solid #6b7280;}\n",
       "\n",
       ".extended-title{\n",
       "  width:100%;\n",
       "}\n",
       "\n",
       "#gsk-overview{\n",
       "  display:flex;\n",
       "}\n",
       "\n",
       "h4 {\n",
       "  font-size: 1rem;\n",
       "  background: #27272A;\n",
       "  padding: 10px;\n",
       "  margin: 0px;\n",
       "  border-bottom: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "  font-size: 1.5rem;\n",
       "  margin-top: 3px;\n",
       "  color:#000000;\n",
       "}\n",
       "\n",
       ".header{\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "}\n",
       ".header > * {\n",
       "  margin-inline: 20px;\n",
       "}\n",
       "\n",
       ".flex-row {\n",
       "  display: flex;\n",
       "  flex-direction: row;\n",
       "  padding:10px;\n",
       "  border: 1px solid #27272A;\n",
       "}\n",
       "\n",
       ".flex-row>div {\n",
       "  flex: auto;\n",
       "  box-sizing: border-box;\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       "progress[value] {\n",
       "  --background: #6D6D6D;\n",
       "  -webkit-appearance: none;\n",
       "  -moz-appearance: none;\n",
       "  appearance: none;\n",
       "  border: none;\n",
       "  height: 4px;\n",
       "  margin: 0 10px;\n",
       "  border-radius: 10em;\n",
       "  background: var(--background);\n",
       "}\n",
       "\n",
       "progress[value]::-webkit-progress-bar {\n",
       "  border-radius: 10em;\n",
       "  background: var(--background);\n",
       "}\n",
       "\n",
       "progress[value]::-webkit-progress-value {\n",
       "  border-radius: 10em;\n",
       "  background: var(--color);\n",
       "}\n",
       "\n",
       "progress[value]::-moz-progress-bar {\n",
       "  border-radius: 10em;\n",
       "  background: var(--color);\n",
       "}\n",
       "\n",
       "label {\n",
       "  font-size: 20px;\n",
       "  font-weight: bold;\n",
       "  display: block;\n",
       "  margin: 20px 0;\n",
       "}\n",
       "\n",
       ".tab {\n",
       "  overflow: hidden;\n",
       "  border: 1px solid #27272A;\n",
       "  background-color: #27272A;\n",
       "}\n",
       "\n",
       ".tab button {\n",
       "  background-color: inherit;\n",
       "  float: left;\n",
       "  border: none;\n",
       "  outline: none;\n",
       "  cursor: pointer;\n",
       "  padding: 14px 16px;\n",
       "  transition: 0.3s;\n",
       "  color: #ffffff;\n",
       "  font-size:1.2rem;\n",
       "}\n",
       "\n",
       ".tab div {\n",
       "  background-color: inherit;\n",
       "  float: left;\n",
       "  border: none;\n",
       "  outline: none;\n",
       "  cursor: pointer;\n",
       "  padding: 14px 16px;\n",
       "  transition: 0.3s;\n",
       "  color: #ffffff;\n",
       "  font-size: 1.2rem;\n",
       "}\n",
       "\n",
       ".tab button:hover {\n",
       "  background-color: #18181B;\n",
       "}\n",
       "\n",
       ".tab-title{\n",
       "  font-size: 1.5rem;\n",
       "  font-weight: bold;\n",
       "  margin-bottom:-5px;\n",
       "}\n",
       "\n",
       ".tab button.active {\n",
       "  background-color: #18181B;\n",
       "  border-top: 1px solid #6b7280;\n",
       "  border-bottom: 1px solid #18181B;\n",
       "  border-left: 1px solid #6b7280;\n",
       "  border-right: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       ".tabcontent {\n",
       "  display: none;\n",
       "  padding: 6px 12px;\n",
       "  background: #18181B;\n",
       "  border: 1px solid #27272A;\n",
       "  border-top: 1px solid #6b7280;\n",
       "  margin-top: -2px;\n",
       "}\n",
       "\n",
       "#gsk-advice {\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "}\n",
       "\n",
       "#gsk-metrics{\n",
       "  width:100%;\n",
       "}\n",
       "\n",
       "#recommendation {\n",
       "  margin-top: 20px;\n",
       "  padding: 20px;\n",
       "  border-radius: 10px;\n",
       "  background-color: #e1ce86;\n",
       "  color: #27272A;\n",
       "  width:95%;\n",
       "  box-shadow: 0 4px 8px 0 #000000, 0 6px 20px 0 #000000;\n",
       "  font-size: 12pt;\n",
       "}\n",
       "\n",
       ".separator {\n",
       "  margin: 20px 0;\n",
       "}\n",
       "\n",
       ".separator-border {\n",
       "  margin: 20px 0;\n",
       "  border-bottom: 1px solid #6b7280;\n",
       "}\n",
       "\n",
       "#gsk-rag{\n",
       "  margin: 32px 28px;\n",
       "  padding: 12px 24px;\n",
       "  background-color: #111516;\n",
       "}\n",
       "\n",
       ".section-container {\n",
       "  margin-bottom: 32px;\n",
       "}\n",
       "\n",
       "  .components-container {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    align-items: flex-start;\n",
       "    gap: 0 32px;\n",
       "  }\n",
       "\n",
       "    .component-card {\n",
       "      background-color: #14191B;\n",
       "      border-radius: 16px;\n",
       "      padding: 28px 32px 32px 32px;\n",
       "      display: flex;\n",
       "      flex-flow: column;\n",
       "      align-items: center;\n",
       "      margin-top: 32px;\n",
       "      flex-grow: 1;\n",
       "    }\n",
       "\n",
       "    .component-title {\n",
       "      font-size: 12px;\n",
       "      font-weight: 500;\n",
       "      color: #B1B1B1;\n",
       "      padding-bottom: 8px;\n",
       "    }\n",
       "\n",
       "    .component-value {\n",
       "      font-size: 32px;\n",
       "      font-weight: 500;\n",
       "      padding-bottom: 12px;\n",
       "    }\n",
       "      \n",
       "      .text-green {\n",
       "        color: #04B543;\n",
       "      }\n",
       "      \n",
       "      .text-orange {\n",
       "        color: #E76E0F;\n",
       "      }\n",
       "      \n",
       "      .text-red {\n",
       "        color: #EA3829;\n",
       "      }\n",
       "\n",
       "      .tooltip {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "      }\n",
       "\n",
       "      .tooltip .tooltiptext {\n",
       "        visibility: hidden;\n",
       "        width: 120px;\n",
       "        background-color: #464646;\n",
       "        color: #E6E6E6;\n",
       "        text-align: center;\n",
       "        border-radius: 6px;\n",
       "        position: absolute;\n",
       "        z-index: 1;\n",
       "        top: 150%;\n",
       "        left: 50%;\n",
       "        margin-left: -60px;\n",
       "        font-size: 12px;\n",
       "        padding: 12px;\n",
       "      }\n",
       "      \n",
       "      .tooltip .tooltiptext::after {\n",
       "        content: \"\";\n",
       "        position: absolute;\n",
       "        bottom: 100%;\n",
       "        left: 50%;\n",
       "        margin-left: -5px;\n",
       "        border-width: 5px;\n",
       "        border-style: solid;\n",
       "        border-color: transparent transparent black transparent;\n",
       "      }\n",
       "      \n",
       "      .tooltip:hover .tooltiptext {\n",
       "        visibility: visible;\n",
       "      }\n",
       "\n",
       "    .overall-card {\n",
       "      background-color: #026836;\n",
       "      border-radius: 16px;\n",
       "      padding: 28px 32px 32px 32px;\n",
       "      display: flex;\n",
       "      flex-flow: column;\n",
       "      align-items: center;\n",
       "      justify-content: center;\n",
       "      margin-top: 32px;\n",
       "      flex-grow: 1;\n",
       "    }\n",
       "  \n",
       "    .overall-title {\n",
       "      font-size: 12px;\n",
       "      font-weight: 500;\n",
       "      color: #E6E6E6;\n",
       "      padding: 14px 0 8px 0;\n",
       "      text-transform: uppercase;\n",
       "     }\n",
       "  \n",
       "    .overall-value {\n",
       "      font-size: 32px;\n",
       "      font-weight: 500;\n",
       "      padding-bottom: 12px;\n",
       "      color: #E6E6E6;\n",
       "    }\n",
       "\n",
       ".section-title {\n",
       "  font-size: 12px;\n",
       "  color: #B1B1B1;\n",
       "  margin-bottom: 20px;\n",
       "  text-align: left;\n",
       "  width: 100%;\n",
       "}\n",
       "\n",
       ".section-content {\n",
       "  color: #E6E6E6;\n",
       "  font-size: 20px;\n",
       "  line-height: 1.5;\n",
       "}\n",
       "\n",
       ".section-card {\n",
       "  background-color: #14191B;\n",
       "  border-radius: 16px;\n",
       "  padding: 28px 32px 32px 32px;\n",
       "  display: flex;\n",
       "  flex-flow: column;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       ".correctness-indicator{\n",
       "  padding: 20px;\n",
       "  border-radius: 50px;\n",
       "  font-size: 16pt;\n",
       "  box-shadow: 0 4px 8px 0 #000000, 0 6px 20px 0 #000000;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".metric-title{\n",
       "  margin: -2px;\n",
       "  border-bottom: none;\n",
       "}\n",
       "\n",
       ".hist-row {\n",
       "  display: flex;\n",
       "  flex-direction: row;\n",
       "  padding: 10px;\n",
       "  justify-content: space-around;\n",
       "  width: 85%;\n",
       "}\n",
       "\n",
       ".hist-row>div {\n",
       "  flex: auto;\n",
       "  box-sizing: border-box;\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "  padding-left: 1%;\n",
       "  padding-right: 1%;\n",
       "}\n",
       "\n",
       ".tab-row{\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       "#component-table{\n",
       "  width:50%;\n",
       "  margin-top: 10px;\n",
       "}\n",
       "\n",
       ".green{\n",
       "  background-color: #0a980a;\n",
       "}\n",
       "\n",
       ".orange {\n",
       "  background-color: #e5b62a;\n",
       "}\n",
       "\n",
       ".red {\n",
       "  background-color: #ba0e0e;\n",
       "}\n",
       "\n",
       ".progress-green {\n",
       "  --color: #04B543;\n",
       "}\n",
       "\n",
       ".progress-orange {\n",
       "  --color: #E76E0F;\n",
       "}\n",
       "\n",
       ".progress-red {\n",
       "  --color: #EA3829;\n",
       "}\n",
       "\n",
       ".corr-plot{\n",
       "  flex: 1;\n",
       "  padding-left: 2%;\n",
       "}\n",
       "\n",
       ".tooltip-text {\n",
       "  position: absolute;\n",
       "  display: none;\n",
       "  visibility: hidden;\n",
       "  z-index: 1;\n",
       "  top: 100%;\n",
       "  left: 0%;\n",
       "  width: 100%;\n",
       "  color: white;\n",
       "  font-size: 12px;\n",
       "  background-color: #2d3d4c;\n",
       "  border-radius: 10px;\n",
       "  padding: 10px 15px 10px 15px;\n",
       "}\n",
       "\n",
       "#fade {\n",
       "  opacity: 1;\n",
       "  transition: opacity 0.5s;\n",
       "}\n",
       "\n",
       "#delay {\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s;\n",
       "  transition-delay: 1s;\n",
       "}\n",
       "\n",
       "td {\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "tr:hover .tooltip-text {\n",
       "  display: block;\n",
       "  visibility: visible;\n",
       "}\n",
       "\n",
       ".tr:hover #fade {\n",
       "  opacity: 1;\n",
       "}\n",
       "\n",
       ".tr:hover #delay {\n",
       "  opacity: 1;\n",
       "}\n",
       "\n",
       ".callout {\n",
       "  padding: 0.5rem 1rem 0.5rem 3rem;\n",
       "  background: #D9EDF9;\n",
       "  border: 3px solid #0088D1;\n",
       "  color: #272eb5;\n",
       "  position: relative;\n",
       "  max-width: 40rem;\n",
       "  border-radius: 10px;\n",
       "  margin-top: 10%;\n",
       "  font-size: 11pt;\n",
       "}\n",
       "\n",
       ".callout-icon {\n",
       "  content: \"\";\n",
       "\n",
       "  /* SVG via a data URI! */\n",
       "  background-size: cover;\n",
       "  width: 1.5rem;\n",
       "  height: 1.5rem;\n",
       "  display: block;\n",
       "  position: absolute;\n",
       "  left: 0.9rem;\n",
       "  top: 1.1rem;\n",
       "}\n",
       "\n",
       ".callout-icon svg{\n",
       "  fill: #016ca7;\n",
       "}\n",
       ".callout p+p {\n",
       "  margin-top: 1em;\n",
       "}\n",
       "\n",
       ".callout a {\n",
       "  color: #272eb5;\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       "#gsk-logo {\n",
       "  padding-top: 10px;\n",
       "}\n",
       "</style>\n",
       "<script src=\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\" integrity=\"sha384-5QIrjQuyo4I/x6DK/Sau33lcA3hT2TCZGr9vbk+2ebd7Da6FnR1amdM+9B5xOrSf\" crossorigin=\"anonymous\"></script>\n",
       "<script src=\"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\" integrity=\"sha384-tXTWPp/bAKa+K9RPuXh7DNvye0Mv+P+6y4rAMVy+pWapsnXg9UG7g20WZ0N4i28A\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"main\">\n",
       "    <div id=\"gsk-rag\" class=\"dark:text-white dark:bg-zinc-800 rounded border border-gray-500\">\n",
       "        <div class=\"header border-b border-b-gray-500\">\n",
       "            \n",
       "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"60\" height=\"30\" viewBox=\"0 0 30 15\" fill=\"none\" id=\"gsk-logo\">\n",
       "                    <path fill=\"#fff\" fill-rule=\"evenodd\"\n",
       "                        d=\"M22.504 1.549a4.196 4.196 0 0 1 2.573-.887v.002a3.783 3.783 0 0 1 2.706 1.086 3.783 3.783 0 0 1 1.126 2.69 3.771 3.771 0 0 1-1.126 2.69 3.77 3.77 0 0 1-2.706 1.085l-4.794.011-2.533 3.467L8.203 15l2.881-3.335a9.829 9.829 0 0 1-4.663-1.68H3.185L0 7.163h3.934C4.263 3.165 8.187 0 12.96 0c2.24 0 4.489.696 6.175 1.909a7.423 7.423 0 0 1 1.882 1.919 4.194 4.194 0 0 1 1.487-2.28ZM7.05 3.249l3.91 3.915h1.505L7.89 2.584a7.773 7.773 0 0 0-.84.665Zm4.079-2.008 5.923 5.923h1.503l-6.086-6.087c-.45.023-.898.078-1.34.164ZM4.574 8.226h-1.77l.784.693h1.584a8.454 8.454 0 0 1-.598-.693Zm9.479 0H5.984c1.469 1.477 3.656 2.377 5.977 2.422l2.092-2.422Zm-2.458 4.472 5.492-1.902 1.878-2.569h-3.508l-3.862 4.47Zm10.361-5.552h3.265a2.714 2.714 0 0 0 1.747-4.648 2.711 2.711 0 0 0-1.888-.773 3.127 3.127 0 0 0-3.123 3.124v2.297Zm3.659-3.73a.677.677 0 1 1-.134 1.348.677.677 0 0 1 .134-1.348Z\"\n",
       "                        clip-rule=\"evenodd\" />\n",
       "                </svg>\n",
       "            <h1>RAG Evaluation Toolkit</h1>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"components-container\">\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">GENERATOR</div>\n",
       "                    <div class=\"component-value tooltip  text-green \">\n",
       "                        80.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Generator is the LLM inside the RAG to generate the answers.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=80.0 class=\" progress-green \">80.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">RETRIEVER</div>\n",
       "                    <div class=\"component-value tooltip  text-orange \">\n",
       "                        66.67%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Retriever fetches relevant documents from the knowledge base according to a user query.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=66.66666666666666 class=\" progress-orange \">66.67%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">REWRITER</div>\n",
       "                    <div class=\"component-value tooltip  text-green \">\n",
       "                        77.78%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Rewriter modifies the user query to match a predefined format or to include the context from the chat history.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=77.77777777777777 class=\" progress-green \">77.78%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">ROUTING</div>\n",
       "                    <div class=\"component-value tooltip  text-green \">\n",
       "                        100.0%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The Router filters the query of the user based on his intentions (intentions detection).</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=100.0 class=\" progress-green \">100.0%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"component-card\">\n",
       "                    <div class=\"component-title\">KNOWLEDGE_BASE</div>\n",
       "                    <div class=\"component-value tooltip  text-orange \">\n",
       "                        65.38%\n",
       "                            <span class=\"tooltiptext\" id=\"fade\">The knowledge base is the set of documents given to the RAG to generate the answers. Its scores is computed differently from the other components: it is the difference between the maximum and minimum correctness score across all the topics of the knowledge base.</span>\n",
       "                    </div>\n",
       "                    <div class=\"component-bar\">\n",
       "                        <progress max=\"100\" value=65.38461538461539 class=\" progress-orange \">65.38%</progress>\n",
       "                    </div>\n",
       "                </div>\n",
       "                \n",
       "                <div class=\"overall-card\">\n",
       "                    <div class=\"overall-title\">Overall Correctness Score</div>\n",
       "                    <div class=\"overall-value\">80%</div>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">RECOMMENDATION</div>\n",
       "                <span class=\"section-content\">Your RAG system&#39;s most critical area for improvement is its handling of distracting elements within queries, which currently yields a very low score of 0.33. Prioritize enhancing your Rewriter&#39;s ability to filter out irrelevant information from user questions to improve upstream processing.</span>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">CORRECTNESS BY TOPIC</div>\n",
       "                    <script type=\"text/javascript\">\n",
       "        (function() {\n",
       "  const fn = function() {\n",
       "    Bokeh.safely(function() {\n",
       "      (function(root) {\n",
       "        function embed_document(root) {\n",
       "        const docs_json = '{\"ea7f313a-d344-4f90-868b-8f054d2eaaca\":{\"version\":\"3.4.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1189\",\"attributes\":{\"height\":350,\"width_policy\":\"max\",\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1191\",\"attributes\":{\"start\":0}},\"y_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1198\",\"attributes\":{\"factors\":[\"Others\",\"Retrieval-Augmented Generation\"]}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1199\"},\"y_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1200\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1196\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1218\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1186\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1187\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1188\"},\"data\":{\"type\":\"map\",\"entries\":[[\"correctness\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAASUB2Yid2YidVQA==\"},\"shape\":[2],\"dtype\":\"float64\",\"order\":\"little\"}],[\"metadata_values\",[\"Others\",\"Retrieval-Augmented Generation\"]],[\"colors\",[\"#a50026\",\"#006837\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1219\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1220\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1215\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1216\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1217\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#14191B\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1227\",\"attributes\":{\"data_source\":{\"id\":\"p1186\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1228\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1229\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1224\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1225\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"p1226\",\"attributes\":{\"y\":{\"type\":\"field\",\"field\":\"metadata_values\"},\"height\":{\"type\":\"value\",\"value\":0.85},\"right\":{\"type\":\"field\",\"field\":\"correctness\"},\"line_color\":{\"type\":\"value\",\"value\":\"white\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"#78BBFA\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1237\",\"attributes\":{\"visible\":false,\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1231\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1232\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1233\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0]],[\"y\",[0]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1238\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1239\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1234\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_width\":2,\"line_dash\":[6]}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1235\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_alpha\":0.1,\"line_width\":2,\"line_dash\":[6]}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1236\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#EA3829\",\"line_alpha\":0.2,\"line_width\":2,\"line_dash\":[6]}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1197\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1211\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"topic\",\"@metadata_values\"],[\"Correctness\",\"@correctness{0.00}\"]]}}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1206\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1207\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1208\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1209\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1201\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1202\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1203\"},\"axis_label\":\"Correctness (%)\",\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1204\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1205\",\"attributes\":{\"axis\":{\"id\":\"p1201\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1210\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1206\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Span\",\"id\":\"p1230\",\"attributes\":{\"location\":80.0,\"dimension\":\"height\",\"line_color\":\"#EA3829\",\"line_width\":2,\"line_dash\":[6]}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1240\",\"attributes\":{\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1241\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Correctness on the entire Testset\"},\"renderers\":[{\"id\":\"p1237\"}]}}]}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}]}}';\n",
       "        const render_items = [{\"docid\":\"ea7f313a-d344-4f90-868b-8f054d2eaaca\",\"roots\":{\"p1189\":\"efe8b21d-ce34-49ae-ab74-9b104a47e032\"},\"root_ids\":[\"p1189\"]}];\n",
       "        root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        }\n",
       "        if (root.Bokeh !== undefined) {\n",
       "          embed_document(root);\n",
       "        } else {\n",
       "          let attempts = 0;\n",
       "          const timer = setInterval(function(root) {\n",
       "            if (root.Bokeh !== undefined) {\n",
       "              clearInterval(timer);\n",
       "              embed_document(root);\n",
       "            } else {\n",
       "              attempts++;\n",
       "              if (attempts > 100) {\n",
       "                clearInterval(timer);\n",
       "                console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "              }\n",
       "            }\n",
       "          }, 10, root)\n",
       "        }\n",
       "      })(window);\n",
       "    });\n",
       "  };\n",
       "  if (document.readyState != \"loading\") fn();\n",
       "  else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "})();\n",
       "    </script>\n",
       "\n",
       "                <div id=\"efe8b21d-ce34-49ae-ab74-9b104a47e032\" data-root-id=\"p1189\" style=\"display: contents;\"></div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "                <div class=\"section-title\">KNOWLEDGE BASE OVERVIEW</div>\n",
       "                    <script type=\"text/javascript\">\n",
       "        (function() {\n",
       "  const fn = function() {\n",
       "    Bokeh.safely(function() {\n",
       "      (function(root) {\n",
       "        function embed_document(root) {\n",
       "        const docs_json = '{\"891f3a4a-e977-4615-858a-4884f08a23a9\":{\"version\":\"3.4.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Tabs\",\"id\":\"p1120\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"tabs\":[{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"p1050\",\"attributes\":{\"title\":\"Topic exploration\",\"child\":{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1004\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1013\",\"attributes\":{\"start\":4.38659131526947,\"end\":11.797508716583252}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1014\",\"attributes\":{\"start\":4.812530279159546,\"end\":11.29534649848938}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1015\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1016\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1011\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1044\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1001\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1002\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1003\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"M7XVQFDt9UAQPgRBuJrtQKEB5UBW4cFAQFgAQWKT6kDQgA1BXL8KQeZHxUC249RAkAwNQSdW+EADEclA4Y+uQDVt8EDeQtVASPi4QNng6EC2Y/1AX6QRQTa9CUEi6QZBMtabQI/7q0CpjpNARSndQNWnvEDAdqpALBinQC04lEBqh/JARd3TQA==\"},\"shape\":[34],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"rb8QQZuq2kAO1g9BI3AjQd4rAUF3kR9BrNEfQf7FF0GiqxVB5uofQfWaCUHHZgFB6XwHQa9kEEEDiABBnGAFQetnCEEU5CBBt40VQdI/5kDdruxACKHvQB9G2UA5o/ZAy0fkQKWQ7kD7ngNBxty+QLo1z0D91NNAdJO8QGQf0UA2DsNAgELZQA==\"},\"shape\":[34],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Others\",\"Others\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Others\",\"Others\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Others\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\"]],[\"id\",[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33]],[\"content\",[\"Retrieval-augmented generation - Wikipedia\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nJump to content\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nMain menu\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nMain menu\\\\nmove to sidebar\\\\nhide\\\\n\\\\n\\\\n\\\\n\\\\t\\\\tNavigation\\\\n\\\\t\\\\n\\\\n\\\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\t\\\\tContribute\\\\n\\\\t\\\\n\\\\n\\\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nAppearance\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nDonate\\\\n\\\\nCreate account\\\\n\\\\nLog in\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPersonal tools\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nDonate Create account Lo...\",\"5\\\\nReferences\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nToggle the table of contents\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nRetrieval-augmented generation\\\\n\\\\n\\\\n\\\\n16 languages\\\\n\\\\n\\\\n\\\\n\\\\n\\\\u0627\\\\u0644\\\\u0639\\\\u0631\\\\u0628\\\\u064a\\\\u0629Catal\\\\u00e0\\\\u010ce\\\\u0161tinaDeutschEspa\\\\u00f1olFran\\\\u00e7aisBahasa IndonesiaItaliano\\\\ud55c\\\\uad6d\\\\uc5b4Polski\\\\u0420\\\\u0443\\\\u0441\\\\u0441\\\\u043a\\\\u0438\\\\u0439\\\\u015al\\\\u016fnskiT\\\\u00fcrk\\\\u00e7e\\\\u0423\\\\u043a\\\\u0440\\\\u0430\\\\u0457\\\\u043d\\\\u0441\\\\u044c\\\\u043a\\\\u0430Ti\\\\u1ebfng Vi\\\\u1ec7t\\\\u4e2d\\\\u6587\\\\n\\\\nEdit links\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nArticleTalk\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nEnglish\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nReadEditView history\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTools\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nTools\\\\nmove to sidebar\\\\nhide\\\\n\\\\n\\\\n\\\\n\\\\t\\\\tActions\\\\n\\\\t\\\\n\\\\n\\\\nReadEditView history\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\t\\\\tGeneral\\\\n\\\\t\\\\n\\\\n\\\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite ...\",\"Type of information retrieval using LLMs\\\\nRetrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information from external data sources.[1] With RAG, LLMs first refer to a specified set of documents, then respond to user queries. These documents supplement information from the LLM&#x27;s pre-existing training data.[2] This allows LLMs to use domain-specific and/or updated information that is not available in the training data.[2] F...\",\"RAG improves large language models (LLMs) by incorporating information retrieval before generating responses.[3] Unlike LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources.[1] According to Ars Technica, \\\\\"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\\\\\" This method helps reduce AI hallucinations,[3] which have caused ...\",\"The term RAG was first introduced in a 2020 research paper.[3]\",\"RAG and LLM limitations[edit]\\\\nLLMs can provide incorrect information. For example, when Google first demonstrated its LLM tool \\\\\"Google Bard\\\\\" (later re-branded to Gemini), the LLM provided incorrect information about the James Webb Space Telescope. This error contributed to a $100 billion decline in the company\\\\u2019s stock value.[4] RAG is used to prevent these errors, but it does not solve all the problems. For example, LLMs can generate misinformation even when pulling from factually correct source...\",\"LLMs with RAG are programmed to prioritize new information. This technique has been called \\\\\"prompt stuffing.\\\\\" Without prompt stuffing, the LLM&#x27;s input is generated by a user; with prompt stuffing, additional relevant context is added to this input to guide the model\\\\u2019s response. This approach provides the LLM with key information early in the prompt, encouraging it to prioritize the supplied data over pre-existing training knowledge.[5]\",\"Process[edit]\\\\nRetrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating an information-retrieval mechanism that allows models to access and utilize additional data beyond their original training set. Ars Technica notes that \\\\\"when new information becomes available, rather than having to retrain the model, all that\\\\u2019s needed is to augment the model\\\\u2019s external knowledge base with the updated information\\\\\" (\\\\\"augmentation\\\\\").[4] IBM states that \\\\\"in the generative phase,...\",\"RAG key stages[edit]\\\\nOverview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\\\\nTypically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of a large vector space. RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs). These embeddings are then stored in a vector database to allow for document retrieval.\\\\nGiven a user query, a document ...\",\"The model feeds this relevant retrieved information into the LLM via prompt engineering of the user&#x27;s original query. Newer implementations (as of 2023[update]) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains and using memory and self-improvement to learn from previous retrievals.\\\\nFinally, the LLM can generate output based on both the query and the retrieved documents.[2][6] Some models incorporate extra steps to improve output, s...\",\"Improvements[edit]\\\\nImprovements to the basic process above can be applied at different stages in the RAG flow. \\\\n\\\\nEncoder[edit]\\\\nThese methods focus on the encoding of text as either dense or sparse vectors. Sparse vectors, which encode the identity of a word, are typically dictionary-length and contain mostly zeros. Dense vectors, which encode meaning, are more compact and contain fewer zeros. Various enhancements can improve the way similarities are calculated in the vector stores (databases).[7...\",\"Performance improves by optimizing how vector similarities are calculated. Dot products enhance similarity scoring, while approximate nearest neighbor (ANN) searches improve retrieval efficiency over K-nearest neighbors (KNN) searches.[8]\\\\nAccuracy may be improved with Late Interactions, which allow the system to compare words more precisely after retrieval. This helps refine document ranking and improve search relevance.[9]\\\\nHybrid vector approaches may be used to combine dense vector representat...\",\"Pre-training the retriever using the Inverse Cloze Task (ICT), a technique that helps the model learn retrieval patterns by predicting masked text within documents.[11]\\\\nSupervised retriever optimization aligns retrieval probabilities with the generator model\\\\u2019s likelihood distribution. This involves retrieving the top-k vectors for a given prompt, scoring the generated response\\\\u2019s perplexity, and minimizing KL divergence between the retriever\\\\u2019s selections and the model\\\\u2019s likelihoods to refine retr...\",\"Retro language model for RAG.  Each Retro block consists of Attention, Chunked Cross Attention, and Feed Forward layers.  Black-lettered boxes show data being changed, and blue lettering shows the algorithm performing the changes.\\\\nBy redesigning the language model with the retriever in mind, a 25-time smaller network can get comparable perplexity as its much larger counterparts.[14] Because it is trained from scratch, this method (Retro) incurs the high cost of training runs that the original RA...\",\"Chunking[edit]\\\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.\\\\n\\\\n\\\\n Different data styles have patterns that correct chunking can take advantage of.\\\\nThree types of chunking strategies are:[citation needed]\",\"Fixed length with overlap. This is fast and easy. Overlapping consecutive chunks helps to maintain semantic context across chunks.\\\\nSyntax-based chunks can break the document up into sentences. Libraries such as spaCy or NLTK can also help.\\\\nFile format-based chunking. Certain file types have natural chunks built in, and it&#x27;s best to respect them. For example, code files are best chunked and vectorized as whole functions or classes. HTML files should leave &lt;table&gt; or base64 encoded &lt;img&gt; elements ...\",\"Evaluation and benchmarks[edit]\\\\nRAG systems are commonly evaluated using benchmarks designed to test retrievability, retrieval accuracy and generative quality. Popular datasets include BEIR, a suite of information retrieval tasks across diverse domains, and Natural Questions or Google QA for open-domain QA.[citation needed]\",\"Challenges[edit]\\\\nRAG does not prevent hallucinations in LLMs. According to Ars Technica, \\\\\"It is not a direct solution because the LLM can still hallucinate around the source material in its response.\\\\\"[4]\\\\nWhile RAG improves the accuracy of large language models (LLMs), it does not eliminate all challenges. One limitation is that while RAG reduces the need for frequent model retraining, it does not remove it entirely. Additionally, LLMs may struggle to recognize when they lack sufficient informati...\",\"RAG poisoning[edit]\\\\nRAG systems may retrieve factually correct but misleading sources, leading to errors in interpretation. In some cases, an LLM may extract statements from a source without considering its context, resulting in an incorrect conclusion. Additionally, when faced with conflicting information, RAG models may struggle to determine which source is accurate. The worst case outcome of this limitation is that the model may combine details from multiple sources producing responses that m...\",\"^ a b c d Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; K\\\\u00fcttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rockt\\\\u00e4schel, Tim; Riedel, Sebastian; Kiela, Douwe (6 December 2020). Retrieval-augmented generation for knowledge-intensive NLP tasks. International Conference on Neural Information Processing Systems. Red Hook, NY, USA: Curran Associates Inc. ISBN\\\\u00a0978-1-7138-2954-6. Retrieved 9 December 2025.\\\\n\\\\n^ a b c d \\\\\"Can a technology called RAG keep AI ...\",\"^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; K\\\\u00fcttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rockt\\\\u00e4schel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \\\\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\\\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459\\\\u20139474. arXiv:2005.11401.\\\\n\\\\n^ a b Luan, Yi; Eisenstein, Jacob; Toutanova, Kristina; Collins, Michael (26 April 2021). \\\\\"Sparse, Dense, and Atten...\",\"^ Khattab, Omar; Zaharia, Matei (2020). \\\\\"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\\\\\". Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. pp.\\\\u00a039\\\\u201348. doi:10.1145/3397271.3401075. ISBN\\\\u00a0978-1-4503-8016-4.\\\\n\\\\n^ Wang, Yup; Conroy, John M.; Molino, Neil; Yang, Julia; Green, Mike (2024). \\\\\"Laboratory for Analytic Sciences in TREC 2024 Retrieval Augmented Generation Track\\\\\". NIST TREC 2024. Retrie...\",\"^ Shi, Weijia; Min, Sewon; Yasunaga, Michihiro; Seo, Minjoon; James, Rich; Lewis, Mike; Zettlemoyer, Luke; Yih, Wen-tau (June 2024). \\\\\"REPLUG: Retrieval-Augmented Black-Box Language Models\\\\\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\\\u00a08371\\\\u20138384. arXiv:2301.12652. doi:10.18653/v1/2024.naacl-long.463. Retrieved 16 March 2025.\\\\n\\\\n^ Ram, Ori; Levine, Yoav; Dalmedigos, Itay; Mu...\",\"^ Wang, Boxin; Ping, Wei; Xu, Peng; McAfee, Lawrence; Liu, Zihan; Shoeybi, Mohammad; Dong, Yi; Kuchaiev, Oleksii; Li, Bo; Xiao, Chaowei; Anandkumar, Anima; Catanzaro, Bryan (2023). \\\\\"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study\\\\\". Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. pp.\\\\u00a07763\\\\u20137786. doi:10.18653/v1/2023.emnlp-main.482.\",\"vteGenerative AIConcepts\\\\nAutoencoder\\\\nDeep learning\\\\nFine-tuning\\\\nFoundation model\\\\nGenerative adversarial network\\\\nGenerative pre-trained transformer\\\\nLarge language model\\\\nModel Context Protocol\\\\nNeural network\\\\nPrompt engineering\\\\nReinforcement learning from human feedback\\\\nRetrieval-augmented generation\\\\nSelf-supervised learning\\\\nSlop\\\\nStochastic parrot\\\\nSynthetic data\\\\nTop-p sampling\\\\nTransformer\\\\nVariational autoencoder\\\\nVibe coding\\\\nVision transformer\\\\nWord embedding\\\\nModelsText\\\\nCharacter.ai\\\\nChatGPT\\\\nCommand\\\\nCl...\",\"LTX-2\\\\nLuma Ray\\\\nRunway Gen\\\\nSeedance\\\\nSora\\\\nVeo\\\\nWan\\\\nSpeech\\\\n15.ai\\\\nEleven\\\\nGemini Speech\\\\nGPT-4o mini TTS\\\\nMiniMax Speech\\\\nSpeechify\\\\nMusic\\\\nEleven Music\\\\nEndel\\\\nLyria\\\\nMiniMax Music\\\\nRiffusion\\\\nStable Audio\\\\nSuno\\\\nUdio\\\\nAgents\\\\nAgentforce\\\\nAutoGLM\\\\nAutoGPT\\\\nChatGPT agent\\\\nDevin AI\\\\nManus\\\\nMiniMax Agent\\\\nOpenAI Codex\\\\nOpenClaw\\\\nReplit Agent\\\\nCompanies\\\\nAdobe\\\\nAleph Alpha\\\\nAnthropic\\\\nAnysphere\\\\nBaichuan\\\\nCanva\\\\nCognition AI\\\\nCohere\\\\nContextual AI\\\\nDeepSeek\\\\nDeepL\\\\nEleutherAI\\\\nElevenLabs\\\\nGoogle DeepMind\\\\nHeyGen\\\\nHugging Face\\\\nInflection AI\\\\nKri...\",\"Voiceverse NFT plagiarism\",\"Category\",\"vteArtificial intelligence (AI)\\\\nHistory\\\\ntimeline\\\\nGlossary\\\\nCompanies\\\\nProjects\\\\nConcepts\\\\nParameter\\\\nHyperparameter\\\\nLoss functions\\\\nRegression\\\\nBias\\\\u2013variance tradeoff\\\\nDouble descent\\\\nOverfitting\\\\nClustering\\\\nGradient descent\\\\nSGD\\\\nQuasi-Newton method\\\\nConjugate gradient method\\\\nBackpropagation\\\\nAttention\\\\nConvolution\\\\nNormalization\\\\nBatchnorm\\\\nActivation\\\\nSoftmax\\\\nSigmoid\\\\nRectifier\\\\nGating\\\\nWeight initialization\\\\nRegularization\\\\nDatasets\\\\nAugmentation\\\\nPrompt engineering\\\\nReinforcement learning\\\\nQ-learning\\\\nSARSA\\\\nImitation\\\\nP...\",\"(Hypothetical: Artificial general intelligence (AGI))\\\\n(Hypothetical: Artificial superintelligence (ASI))\\\\nImplementationsAudio\\\\u2013visual\\\\nAlexNet\\\\nWaveNet\\\\nHuman image synthesis\\\\nHWR\\\\nOCR\\\\nComputer vision\\\\nSpeech synthesis\\\\n15.ai\\\\nElevenLabs\\\\nSpeech recognition\\\\nWhisper\\\\nFacial recognition\\\\nAlphaFold\\\\nText-to-image models\\\\nAurora\\\\nDALL-E\\\\nFirefly\\\\nFlux\\\\nGPT Image\\\\nIdeogram\\\\nImagen\\\\nMidjourney\\\\nRecraft\\\\nStable Diffusion\\\\nText-to-video models\\\\nDream Machine\\\\nRunway Gen\\\\nHailuo AI\\\\nKling\\\\nSora\\\\nSeedance\\\\nVeo\\\\nMusic generation\\\\nRiffusio...\",\"Shun&#x27;ichi Amari\\\\nKunihiko Fukushima\\\\nTakeo Kanade\\\\nMarvin Minsky\\\\nJohn McCarthy\\\\nNathaniel Rochester\\\\nAllen Newell\\\\nCliff Shaw\\\\nHerbert A. Simon\\\\nOliver Selfridge\\\\nFrank Rosenblatt\\\\nBernard Widrow\\\\nJoseph Weizenbaum\\\\nSeymour Papert\\\\nSeppo Linnainmaa\\\\nPaul Werbos\\\\nGeoffrey Hinton\\\\nJohn Hopfield\\\\nJ\\\\u00fcrgen Schmidhuber\\\\nYann LeCun\\\\nYoshua Bengio\\\\nLotfi A. Zadeh\\\\nStephen Grossberg\\\\nAlex Graves\\\\nJames Goodnight\\\\nAndrew Ng\\\\nFei-Fei Li\\\\nAlex Krizhevsky\\\\nIlya Sutskever\\\\nOriol Vinyals\\\\nQuoc V. Le\\\\nIan Goodfellow\\\\nDemis Hassabis\\\\nDavid Silv...\",\"Mamba\\\\nAutoencoder\\\\nVariational autoencoder (VAE)\\\\nGenerative adversarial network (GAN)\\\\nGraph neural network (GNN)\\\\nPolitical\\\\nAI safety (Alignment)\\\\nEthics of AI\\\\nEU AI Act\\\\nPrecautionary principle\\\\nRegulation of AI\\\\nSocial and economic\\\\nAI boom\\\\nAI bubble\\\\nAI literacy\\\\nAI slop\\\\nAI winter\\\\nAnthropomorphism\\\\nIn architecture\\\\nIn education\\\\nIn healthcare\\\\nChatbot psychosis\\\\nMental health\\\\nIn visual art\",\"Category\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nRetrieved from \\\\\"https://en.wikipedia.org/w/index.php?title=Retrieval-augmented_generation&amp;oldid=1337298272\\\\\"\\\\nCategories: Large language modelsNatural language processingInformation retrieval systemsGenerative artificial intelligenceHidden categories: Articles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2023All articles containing potentially dated statementsAll articles with unsourced statementsArticles with...\",\"Privacy policy\\\\nAbout Wikipedia\\\\nDisclaimers\\\\nContact Wikipedia\\\\nLegal &amp; safety contacts\\\\nCode of Conduct\\\\nDevelopers\\\\nStatistics\\\\nCookie statement\\\\nMobile view\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nToggle the table of contents\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nRetrieval-augmented generation\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n16 languages\\\\n\\\\n\\\\nAdd topic\"]],[\"color\",{\"type\":\"ndarray\",\"array\":[\"#1f77b4\",\"#aec7e8\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#1f77b4\",\"#aec7e8\",\"#aec7e8\",\"#999\",\"#999\",\"#aec7e8\",\"#aec7e8\",\"#aec7e8\",\"#999\",\"#999\",\"#aec7e8\",\"#aec7e8\",\"#999\",\"#aec7e8\",\"#aec7e8\",\"#aec7e8\"],\"shape\":[34],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1045\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1046\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1041\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1042\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1043\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1012\",\"attributes\":{\"logo\":\"grey\",\"tools\":[{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1027\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":\"\\\\n    &lt;div style=\\\\\"width:400px;\\\\\"&gt;\\\\n    &lt;b&gt;Document id:&lt;/b&gt; @id &lt;br&gt;\\\\n    &lt;b&gt;Topic:&lt;/b&gt; @topic &lt;br&gt;\\\\n    &lt;b&gt;Document Content:&lt;/b&gt; @content\\\\n    &lt;/div&gt;\\\\n    \"}},{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1028\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1029\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1030\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1031\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1036\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1037\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1022\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1023\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1024\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1025\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1017\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1018\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1019\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1020\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1021\",\"attributes\":{\"axis\":{\"id\":\"p1017\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1026\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1022\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1047\",\"attributes\":{\"title\":\"Knowledge Base Tospics\",\"title_text_color\":\"#B1B1B1\",\"title_text_font_style\":\"bold\",\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1048\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Others\"},\"renderers\":[{\"id\":\"p1044\"}],\"index\":21}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1049\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Retrieval-Augmented Generation\"},\"renderers\":[{\"id\":\"p1044\"}],\"index\":0}}]}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}}},{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"p1119\",\"attributes\":{\"title\":\"Failures\",\"child\":{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1055\",\"attributes\":{\"sizing_mode\":\"stretch_width\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1064\",\"attributes\":{\"start\":4.38659131526947,\"end\":11.797508716583252}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1065\",\"attributes\":{\"start\":4.812530279159546,\"end\":11.29534649848938}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1066\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1067\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1062\",\"attributes\":{\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"14pt\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1094\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1051\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1052\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1053\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"LTiUQGKT6kDeQtVANW3wQKmOk0C4mu1AMtabQEUp3UDVp7xASPi4QLZj/UBF3dNA0IANQRA+BEGhAeVA\"},\"shape\":[15],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"ZB/RQP7FF0EU5CBB62cIQfueA0EjcCNBy0fkQMbcvkC6Nc9At40VQd2u7ECAQtlAoqsVQQ7WD0HeKwFB\"},\"shape\":[15],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Others\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Others\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\"]],[\"correctness\",[true,true,true,false,true,true,true,false,false,true,true,true,true,true,true]],[\"questions\",[\"What political topics are mentioned in the provided list?\",\"How does Retrieval-Augmented Generation (RAG) enhance large language models (LLMs)?\",\"According to IBM, what is a reason why large language models (LLMs) might generate answers even when they should indicate uncertainty?\",\"Considering RAG system evaluation involves retrievability and generative quality, which popular datasets are employed for these benchmarks, specifically for open-domain QA?\",\"Considering the provided document&#x27;s title, what specific topic, concerning digital intellectual property, is highlighted?\",\"Beyond merely reducing computational and financial costs, what specific problem related to factual inaccuracies, like generating non-existent policies or legal cases, does Retrieval-Augmented Generation (RAG) primarily help mitigate in large language models?\",\"Given that the Wikipedia page&#x27;s primary topic is &#x27;Retrieval-augmented generation&#x27;, what are some of the concepts related to Generative AI that are likely to be discussed or listed within that specific article?\",\"Considering its detailed discussion of RAG-related language models such as Retro and Retro++, what category would best describe this document?\",\"Given the Wikipedia page&#x27;s categorization structure, which main category, specifically excluding any listed under &#x27;Hidden categories&#x27;, is Retrieval-Augmented Generation (RAG) primarily associated with?\",\"Hey there! I&#x27;m a student currently researching vulnerabilities in AI systems, particularly how they might struggle with diverse or conflicting information sources. I came across the term &#x27;RAG poisoning&#x27; and was wondering, according to the MIT Technology Review, what&#x27;s the underlying reason for issues like that in RAG systems?\",\"Hey! I&#x27;m a graduate student currently preparing a presentation on advanced NLP techniques, and I&#x27;m particularly interested in discussing hybrid generation models like RAG. To properly cite my sources, could you please tell me, who are the authors of the paper titled \\\\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\\\"?\",\"What is the primary subject of this page, and in how many languages is this topic available?\",\"What is the primary function of the RAG process, and how is data prepared and stored for document retrieval within this system?\",\"What is it?\",\"When was it first introduced?\"]],[\"agent_answer\",[\"The political topics mentioned in the provided list are:\\\\n*   AI safety (Alignment)\\\\n*   Ethics of AI\\\\n*   EU AI Act\\\\n*   Precautionary principle\\\\n*   Regulation of AI\",\"Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by incorporating an information retrieval mechanism before generating responses. This allows LLMs to:\\\\n\\\\n*   **Access and utilize additional data:** RAG pulls relevant text from external sources like databases, uploaded documents, or web sources, going beyond the LLM&#x27;s original, static training data.\\\\n*   **Supplement existing knowledge:** The retrieved documents supplement the information from the LLM&#x27;s pre-existing training data, enabling it to use domain-specific and/or updated information not available in its initial training.\\\\n*   **Reduce AI hallucinations:** By grounding responses in retrieved facts, RAG helps LLMs stick to the facts and reduces the likelihood of generating incorrect or nonexistent information.\\\\n*   **Reduce retraining needs:** When new information becomes available, RAG allows for augmenting the model&#x27;s external knowledge base instead of requiring a full retraining of the LLM, saving computational and financial costs.\\\\n*   **Increase transparency:** LLMs can include sources in their responses, allowing users to verify the cited information and cross-check for accuracy and relevance.\\\\n\\\\nThe retrieved information is fed into the LLM via prompt engineering of the user&#x27;s original query, enabling the LLM to generate output based on both the query and the retrieved documents.\",\"According to IBM, large language models (LLMs) might generate answers even when they should indicate uncertainty when the model lacks the ability to assess its own knowledge limitations.\",\"For open-domain QA, popular datasets employed for RAG system evaluation benchmarks include Natural Questions or Google QA.\",\"The specific topic concerning digital intellectual property highlighted is **Voiceverse NFT plagiarism**.\",\"Retrieval-Augmented Generation (RAG) primarily helps mitigate AI hallucinations, which are factual inaccuracies where chatbots describe policies that don&#x27;t exist or recommend nonexistent legal cases.\",\"Based on the context, the Wikipedia page on &#x27;Retrieval-augmented generation&#x27; is categorized under &#x27;Generative artificial intelligence&#x27;. Therefore, concepts related to Generative AI that are likely to be discussed or listed within that article include:\\\\n\\\\n*   Autoencoder\\\\n*   Deep learning\\\\n*   Fine-tuning\\\\n*   Foundation model\\\\n*   Generative adversarial network\\\\n*   Generative pre-trained transformer\\\\n*   Large language model\\\\n*   Model Context Protocol\\\\n*   Neural network\\\\n*   Prompt engineering\\\\n*   Reinforcement learning from human feedback\\\\n*   Retrieval-augmented generation\\\\n*   Self-supervised learning\\\\n*   Slop\\\\n*   Stochastic parrot\\\\n*   Synthetic data\\\\n*   Top-p sampling\\\\n*   Transformer\\\\n*   Variational autoencoder\\\\n*   Vibe coding\\\\n*   Vision transformer\\\\n*   Word embedding\",\"Based on the context, the document would best be described by categories such as **Large language models**, **Natural language processing**, **Information retrieval systems**, or **Generative artificial intelligence**. Given the detailed discussion of RAG-related language models like Retro and Retro++, **Large language models** or **Natural language processing** would be particularly fitting.\",\"Retrieval-Augmented Generation (RAG) is primarily associated with the following main categories, excluding hidden ones:\\\\n\\\\n*   Large language models\\\\n*   Natural language processing\\\\n*   Information retrieval systems\\\\n*   Generative artificial intelligence\",\"According to the MIT Technology Review, issues like RAG poisoning occur because RAG systems may misinterpret the data they retrieve.\",\"The authors of the paper titled \\\\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\\\" are:\\\\n\\\\n*   Patrick Lewis\\\\n*   Ethan Perez\\\\n*   Aleksandra Piktus\\\\n*   Fabio Petroni\\\\n*   Vladimir Karpukhin\\\\n*   Naman Goyal\\\\n*   Heinrich K\\\\u00fcttler\\\\n*   Mike Lewis\\\\n*   Wen-tau Yih\\\\n*   Tim Rockt\\\\u00e4schel\\\\n*   Sebastian Riedel\\\\n*   Douwe Kiela\",\"The primary subject of this page is Retrieval-augmented generation, and this topic is available in 16 languages.\",\"The primary function of the RAG process is to enhance large language models (LLMs) by enabling them to retrieve and incorporate new information from external data sources. This allows LLMs to use domain-specific and/or updated information not available in their original training data, helping them stick to facts, reduce AI hallucinations, and provide greater transparency by including sources.\\\\n\\\\nFor document retrieval, the data to be referenced is typically converted into LLM embeddings, which are numerical representations in the form of a large vector space. These embeddings are then stored in a vector database.\",\"Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information from external data sources. With RAG, LLMs first refer to a specified set of documents, then respond to user queries, supplementing information from the LLM&#x27;s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in their training data.\",\"It was first introduced in 2020.\"]],[\"reference_answer\",[\"The political topics mentioned are AI safety (Alignment), Ethics of AI, EU AI Act, Precautionary principle, and Regulation of AI.\",\"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating an information-retrieval mechanism that allows models to access and utilize additional data beyond their original training set.\",\"According to IBM, this issue can arise when the model lacks the ability to assess its own knowledge limitations.\",\"Popular datasets include BEIR, a suite of information retrieval tasks across diverse domains, and Natural Questions or Google QA for open-domain QA.\",\"Voiceverse NFT plagiarism\",\"Retrieval-Augmented Generation (RAG) helps reduce AI hallucinations.\",\"Some concepts related to Generative AI include Autoencoder, Deep learning, Fine-tuning, Foundation model, Generative adversarial network, Generative pre-trained transformer, Large language model, Model Context Protocol, Neural network, Prompt engineering, Reinforcement learning from human feedback, Retrieval-augmented generation, Self-supervised learning, Slop, Stochastic parrot, Synthetic data, Top-p sampling, Transformer, Variational autoencoder, Vibe coding, Vision transformer, and Word embedding.\",\"The provided context does not contain information about its category.\",\"RAG is listed under the &#x27;Concepts&#x27; category.\",\"According to the MIT Technology Review, these issues occur because RAG systems may misinterpret the data they retrieve.\",\"The authors are Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\\\\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\\\\u00e4schel, Sebastian Riedel, and Douwe Kiela.\",\"The primary subject of this page is Retrieval-augmented generation, and this topic is available in 16 languages.\",\"The RAG process primarily combines external documents and user input into an LLM prompt to get tailored output. For document retrieval, data is typically converted into LLM embeddings, which are numerical representations, and then stored in a vector database.\",\"Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information from external data sources.\",\"The term RAG was first introduced in a 2020 research paper.\"]],[\"id\",[31,7,17,16,26,3,24,27,28,18,20,33,8,2,4]],[\"content\",[\"Mamba\\\\nAutoencoder\\\\nVariational autoencoder (VAE)\\\\nGenerative adversarial network (GAN)\\\\nGraph neural network (GNN)\\\\nPolitical\\\\nAI safety (Alignment)\\\\nEthics of AI\\\\nEU AI Act\\\\nPrecautionary principle\\\\nRegulation of AI\\\\nSocial and economic\\\\nAI boom\\\\nAI bubble\\\\nAI literacy\\\\nAI slop\\\\nAI winter\\\\nAnthropomorphism\\\\nIn architecture\\\\nIn education\\\\nIn healthcare\\\\nChatbot psychosis\\\\nMental health\\\\nIn visual art\",\"Process[edit]\\\\nRetrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating an information-retrieval mechanism that allows models to access and utilize additional data beyond their original training set. Ars Technica notes that \\\\\"when new information becomes available, rather than having to retrain the model, all that\\\\u2019s needed is to augment the model\\\\u2019s external knowledge base with the updated information\\\\\" (\\\\\"augmentation\\\\\").[4] IBM states that \\\\\"in the generative phase,...\",\"Challenges[edit]\\\\nRAG does not prevent hallucinations in LLMs. According to Ars Technica, \\\\\"It is not a direct solution because the LLM can still hallucinate around the source material in its response.\\\\\"[4]\\\\nWhile RAG improves the accuracy of large language models (LLMs), it does not eliminate all challenges. One limitation is that while RAG reduces the need for frequent model retraining, it does not remove it entirely. Additionally, LLMs may struggle to recognize when they lack sufficient informati...\",\"Evaluation and benchmarks[edit]\\\\nRAG systems are commonly evaluated using benchmarks designed to test retrievability, retrieval accuracy and generative quality. Popular datasets include BEIR, a suite of information retrieval tasks across diverse domains, and Natural Questions or Google QA for open-domain QA.[citation needed]\",\"Voiceverse NFT plagiarism\",\"RAG improves large language models (LLMs) by incorporating information retrieval before generating responses.[3] Unlike LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources.[1] According to Ars Technica, \\\\\"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\\\\\" This method helps reduce AI hallucinations,[3] which have caused ...\",\"vteGenerative AIConcepts\\\\nAutoencoder\\\\nDeep learning\\\\nFine-tuning\\\\nFoundation model\\\\nGenerative adversarial network\\\\nGenerative pre-trained transformer\\\\nLarge language model\\\\nModel Context Protocol\\\\nNeural network\\\\nPrompt engineering\\\\nReinforcement learning from human feedback\\\\nRetrieval-augmented generation\\\\nSelf-supervised learning\\\\nSlop\\\\nStochastic parrot\\\\nSynthetic data\\\\nTop-p sampling\\\\nTransformer\\\\nVariational autoencoder\\\\nVibe coding\\\\nVision transformer\\\\nWord embedding\\\\nModelsText\\\\nCharacter.ai\\\\nChatGPT\\\\nCommand\\\\nCl...\",\"Category\",\"vteArtificial intelligence (AI)\\\\nHistory\\\\ntimeline\\\\nGlossary\\\\nCompanies\\\\nProjects\\\\nConcepts\\\\nParameter\\\\nHyperparameter\\\\nLoss functions\\\\nRegression\\\\nBias\\\\u2013variance tradeoff\\\\nDouble descent\\\\nOverfitting\\\\nClustering\\\\nGradient descent\\\\nSGD\\\\nQuasi-Newton method\\\\nConjugate gradient method\\\\nBackpropagation\\\\nAttention\\\\nConvolution\\\\nNormalization\\\\nBatchnorm\\\\nActivation\\\\nSoftmax\\\\nSigmoid\\\\nRectifier\\\\nGating\\\\nWeight initialization\\\\nRegularization\\\\nDatasets\\\\nAugmentation\\\\nPrompt engineering\\\\nReinforcement learning\\\\nQ-learning\\\\nSARSA\\\\nImitation\\\\nP...\",\"RAG poisoning[edit]\\\\nRAG systems may retrieve factually correct but misleading sources, leading to errors in interpretation. In some cases, an LLM may extract statements from a source without considering its context, resulting in an incorrect conclusion. Additionally, when faced with conflicting information, RAG models may struggle to determine which source is accurate. The worst case outcome of this limitation is that the model may combine details from multiple sources producing responses that m...\",\"^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; K\\\\u00fcttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rockt\\\\u00e4schel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \\\\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\\\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459\\\\u20139474. arXiv:2005.11401.\\\\n\\\\n^ a b Luan, Yi; Eisenstein, Jacob; Toutanova, Kristina; Collins, Michael (26 April 2021). \\\\\"Sparse, Dense, and Atten...\",\"Privacy policy\\\\nAbout Wikipedia\\\\nDisclaimers\\\\nContact Wikipedia\\\\nLegal &amp; safety contacts\\\\nCode of Conduct\\\\nDevelopers\\\\nStatistics\\\\nCookie statement\\\\nMobile view\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nToggle the table of contents\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nRetrieval-augmented generation\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n16 languages\\\\n\\\\n\\\\nAdd topic\",\"RAG key stages[edit]\\\\nOverview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\\\\nTypically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of a large vector space. RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs). These embeddings are then stored in a vector database to allow for document retrieval.\\\\nGiven a user query, a document ...\",\"Type of information retrieval using LLMs\\\\nRetrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information from external data sources.[1] With RAG, LLMs first refer to a specified set of documents, then respond to user queries. These documents supplement information from the LLM&#x27;s pre-existing training data.[2] This allows LLMs to use domain-specific and/or updated information that is not available in the training data.[2] F...\",\"The term RAG was first introduced in a 2020 research paper.[3]\"]],[\"color\",[\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#ba0e0e\",\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#ba0e0e\",\"#ba0e0e\",\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#0a980a\",\"#0a980a\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1095\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1096\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1091\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.7},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.7}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1092\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1093\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1109\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1100\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1101\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1102\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"M7XVQFDt9UAQPgRBuJrtQKEB5UBW4cFAQFgAQWKT6kDQgA1BXL8KQeZHxUC249RAkAwNQSdW+EADEclA4Y+uQDVt8EDeQtVASPi4QNng6EC2Y/1AX6QRQTa9CUEi6QZBMtabQI/7q0CpjpNARSndQNWnvEDAdqpALBinQC04lEBqh/JARd3TQA==\"},\"shape\":[34],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"rb8QQZuq2kAO1g9BI3AjQd4rAUF3kR9BrNEfQf7FF0GiqxVB5uofQfWaCUHHZgFB6XwHQa9kEEEDiABBnGAFQetnCEEU5CBBt40VQdI/5kDdruxACKHvQB9G2UA5o/ZAy0fkQKWQ7kD7ngNBxty+QLo1z0D91NNAdJO8QGQf0UA2DsNAgELZQA==\"},\"shape\":[34],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1110\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1111\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1106\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1107\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1108\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":6},\"line_color\":{\"type\":\"value\",\"value\":\"grey\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"grey\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1063\",\"attributes\":{\"logo\":\"grey\",\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1078\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1079\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1080\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1081\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1086\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1087\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1054\",\"attributes\":{\"renderers\":[{\"id\":\"p1094\"}],\"tooltips\":\"\\\\n    &lt;div style=\\\\\"width:400px;\\\\\"&gt;\\\\n    &lt;b&gt;Document id:&lt;/b&gt; @id &lt;br&gt;\\\\n    &lt;b&gt;Topic:&lt;/b&gt; @topic &lt;br&gt;\\\\n    &lt;b&gt;Question:&lt;/b&gt; @questions &lt;br&gt;\\\\n    &lt;b&gt;agent Answer:&lt;/b&gt; @agent_answer &lt;br&gt;\\\\n    &lt;b&gt;Reference Answer:&lt;/b&gt; @reference_answer &lt;br&gt;\\\\n    &lt;b&gt;Correctness:&lt;/b&gt; @correctness &lt;br&gt;\\\\n    &lt;b&gt;Content:&lt;/b&gt; @content\\\\n    &lt;/div&gt;\\\\n    \"}}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1073\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1074\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1075\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1076\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1068\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1069\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1070\"},\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1071\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1072\",\"attributes\":{\"axis\":{\"id\":\"p1068\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1077\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1073\"},\"grid_line_color\":\"white\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1097\",\"attributes\":{\"title\":\"Question Correctness\",\"title_text_color\":\"#B1B1B1\",\"title_text_font_style\":\"bold\",\"border_line_alpha\":0,\"background_fill_color\":\"#111516\",\"background_fill_alpha\":0.5,\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1098\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"False\"},\"renderers\":[{\"id\":\"p1094\"}],\"index\":3}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1099\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"True\"},\"renderers\":[{\"id\":\"p1094\"}],\"index\":0}}]}},{\"type\":\"object\",\"name\":\"LabelSet\",\"id\":\"p1115\",\"attributes\":{\"level\":\"glyph\",\"source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1112\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1113\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1114\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"9UvmQAlT0EA=\"},\"shape\":[2],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"82sRQUDH3UA=\"},\"shape\":[2],\"dtype\":\"float32\",\"order\":\"little\"}],[\"topic\",[\"Retrieval-Augmented Generation\",\"Retrieval-Augmented Generation\"]]]}}},\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"text\":{\"type\":\"field\",\"field\":\"topic\"},\"text_color\":{\"type\":\"value\",\"value\":\"#B1B1B1\"},\"text_font_size\":{\"type\":\"value\",\"value\":\"12pt\"},\"text_font_style\":{\"type\":\"value\",\"value\":\"bold\"},\"text_align\":{\"type\":\"value\",\"value\":\"center\"}}}],\"background_fill_color\":\"#14191B\",\"border_fill_color\":\"#15191C\"}}}}],\"tabs_location\":\"below\"}}]}}';\n",
       "        const render_items = [{\"docid\":\"891f3a4a-e977-4615-858a-4884f08a23a9\",\"roots\":{\"p1120\":\"d11d6c30-512f-4dda-bb79-173e71e3809e\"},\"root_ids\":[\"p1120\"]}];\n",
       "        root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        }\n",
       "        if (root.Bokeh !== undefined) {\n",
       "          embed_document(root);\n",
       "        } else {\n",
       "          let attempts = 0;\n",
       "          const timer = setInterval(function(root) {\n",
       "            if (root.Bokeh !== undefined) {\n",
       "              clearInterval(timer);\n",
       "              embed_document(root);\n",
       "            } else {\n",
       "              attempts++;\n",
       "              if (attempts > 100) {\n",
       "                clearInterval(timer);\n",
       "                console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "              }\n",
       "            }\n",
       "          }, 10, root)\n",
       "        }\n",
       "      })(window);\n",
       "    });\n",
       "  };\n",
       "  if (document.readyState != \"loading\") fn();\n",
       "  else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "})();\n",
       "    </script>\n",
       "\n",
       "                <div id=\"d11d6c30-512f-4dda-bb79-173e71e3809e\" data-root-id=\"p1120\" style=\"display: contents;\"></div>\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"section-container\">\n",
       "            <div class=\"section-card\">\n",
       "\n",
       "                <div class=\"section-title\">SELECTED METRICS</div>\n",
       "\n",
       "                \n",
       "\n",
       "            </div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "    </div>\n",
       "</div>\n",
       "\n",
       "\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "    function opentab(evt, name) {\n",
       "    // Declare all variables\n",
       "    let i, tabcontent, tablinks;\n",
       "\n",
       "    // Get all elements with class=\"tabcontent\" and hide them\n",
       "    tabcontent = document.getElementsByClassName(\"tabcontent\");\n",
       "    for (i = 0; i < tabcontent.length; i++) {\n",
       "        tabcontent[i].style.display = \"none\";\n",
       "    }\n",
       "\n",
       "    // Get all elements with class=\"tablinks\" and remove the class \"active\"\n",
       "    tablinks = document.getElementsByClassName(\"tablinks\");\n",
       "    for (i = 0; i < tablinks.length; i++) {\n",
       "        tablinks[i].className = tablinks[i].className.replace(\" active\", \"\");\n",
       "    }\n",
       "\n",
       "    // Show the current tab, and add an \"active\" class to the button that opened the tab\n",
       "    document.getElementById(name).style.display = \"block\";\n",
       "    evt.currentTarget.className += \" active\";\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<giskard.rag.report.RAGReport at 0x723351fef610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create a simple Python function that takes a question and returns an answer\n",
    "def answer_fn(question: str, history=None) -> str:\n",
    "    # Notice we use .invoke() here for a single question\n",
    "    return chain.invoke({\"question\": question})\n",
    "\n",
    "# 2. Evaluate!\n",
    "from giskard.rag import evaluate\n",
    "\n",
    "report = evaluate(\n",
    "    answer_fn=answer_fn, \n",
    "    testset=testset, \n",
    "    knowledge_base=knowledge_base\n",
    ")\n",
    "\n",
    "# Display report natively in the notebook\n",
    "display(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15b5b3-c166-4dfc-b57e-756e225c7204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
